# Diffusion modelï¼šDiT, transformer only

æ‰©æ•£æ¨¡å‹å¤§éƒ¨åˆ†æ˜¯é‡‡ç”¨**UNetæ¶æ„**æ¥è¿›è¡Œå»ºæ¨¡ï¼ŒUNetå¯ä»¥å®ç°è¾“å‡ºå’Œè¾“å…¥ä¸€æ ·ç»´åº¦ï¼Œæ‰€ä»¥å¤©ç„¶é€‚åˆæ‰©æ•£æ¨¡å‹ã€‚æ‰©æ•£æ¨¡å‹ä½¿ç”¨çš„UNeté™¤äº†åŒ…å«åŸºäºæ®‹å·®çš„å·ç§¯æ¨¡å—ï¼ŒåŒæ—¶ä¹Ÿå¾€å¾€é‡‡ç”¨self-attentionã€‚è‡ªä»ViTä¹‹åï¼Œtransformeræ¶æ„å·²ç»å¤§é‡åº”ç”¨åœ¨å›¾åƒä»»åŠ¡ä¸Šï¼Œéšç€æ‰©æ•£æ¨¡å‹çš„æµè¡Œï¼Œä¹Ÿå·²ç»æœ‰å·¥ä½œå°è¯•é‡‡ç”¨transformeræ¶æ„æ¥å¯¹æ‰©æ•£æ¨¡å‹å»ºæ¨¡ï¼Œè¿™ç¯‡æ–‡ç« æˆ‘ä»¬å°†ä»‹ç»Metaçš„å·¥ä½œ**DiT**ï¼š[**Scalable Diffusion Models with Transformers**](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2212.09748)ï¼Œå®ƒæ˜¯**å®Œå…¨åŸºäºtransformeræ¶æ„çš„æ‰©æ•£æ¨¡å‹**ï¼Œè¿™ä¸ªå·¥ä½œä¸ä»…å°†transformeræˆåŠŸåº”ç”¨åœ¨æ‰©æ•£æ¨¡å‹ï¼Œè¿˜æ¢ç©¶äº†**transformeræ¶æ„åœ¨æ‰©æ•£æ¨¡å‹ä¸Šçš„scalabilityèƒ½åŠ›**ï¼Œ**å…¶ä¸­æœ€å¤§çš„æ¨¡å‹DiT-XL/2åœ¨ImageNet 256x256çš„ç±»åˆ«æ¡ä»¶ç”Ÿæˆä¸Šè¾¾åˆ°äº†SOTAï¼ˆFIDä¸º2.27ï¼‰**ã€‚

![Untitled](Diffusion%20model%EF%BC%9ADiT,%20transformer%20only%208a22b30972f343d0befe0f0a373d8387/Untitled.png)

åœ¨ä»‹ç»DiTæ¨¡å‹æ¶æ„ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆæ¥çœ‹ä¸€ä¸‹DiTæ‰€é‡‡ç”¨çš„æ‰©æ•£æ¨¡å‹ã€‚ é¦–å…ˆï¼ŒDiTå¹¶æ²¡æœ‰é‡‡ç”¨å¸¸è§„çš„pixel diffusionï¼Œè€Œæ˜¯**é‡‡ç”¨äº†latent diffusionæ¶æ„**ï¼Œè¿™ä¹Ÿæ˜¯Stable Diffusionæ‰€é‡‡ç”¨çš„æ¶æ„ã€‚latent diffusioné‡‡ç”¨ä¸€ä¸ªautoencoderæ¥å°†å›¾åƒå‹ç¼©ä¸ºä½ç»´åº¦çš„latentï¼Œæ‰©æ•£æ¨¡å‹ç”¨æ¥ç”Ÿæˆlatentï¼Œç„¶åå†é‡‡ç”¨autoencoderæ¥é‡å»ºå‡ºå›¾åƒã€‚DiTé‡‡ç”¨çš„autoencoderæ˜¯SDæ‰€ä½¿ç”¨çš„KL-f8ï¼Œå¯¹äº256x256x3çš„å›¾åƒï¼Œå…¶å‹ç¼©å¾—åˆ°çš„latentå¤§å°ä¸º32x32x4ï¼Œè¿™å°±é™ä½äº†æ‰©æ•£æ¨¡å‹çš„è®¡ç®—é‡ï¼ˆåé¢æˆ‘ä»¬ä¼šçœ‹åˆ°è¿™å°†å‡å°‘transformerçš„tokenæ•°é‡ï¼‰ã€‚å¦å¤–ï¼Œè¿™é‡Œæ‰©æ•£è¿‡ç¨‹çš„nosie scheduleré‡‡ç”¨ç®€å•çš„linear schedulerï¼ˆtimesteps=1000ï¼Œbeta_start=0.0001ï¼Œbeta_end=0.02ï¼‰ï¼Œè¿™ä¸ªå’ŒSDæ˜¯ä¸åŒçš„ã€‚ å…¶æ¬¡ï¼ŒDiTæ‰€ä½¿ç”¨çš„æ‰©æ•£æ¨¡å‹æ²¿ç”¨äº†OpenAIçš„[**Improved DDPM**](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2102.09672)ï¼Œç›¸æ¯”åŸå§‹DDPMä¸€ä¸ªé‡è¦çš„å˜åŒ–æ˜¯ä¸å†é‡‡ç”¨å›ºå®šçš„æ–¹å·®ï¼Œè€Œæ˜¯**é‡‡ç”¨ç½‘ç»œæ¥é¢„æµ‹æ–¹å·®**ã€‚åœ¨DDPMä¸­ï¼Œç”Ÿæˆè¿‡ç¨‹çš„åˆ†å¸ƒé‡‡ç”¨ä¸€ä¸ªå‚æ•°åŒ–çš„é«˜æ–¯åˆ†å¸ƒæ¥å»ºæ¨¡ï¼š

![Untitled](Diffusion%20model%EF%BC%9ADiT,%20transformer%20only%208a22b30972f343d0befe0f0a373d8387/Untitled%201.png)

ä¸Šé¢ä»‹ç»å®Œäº†DiTæ‰€é‡‡ç”¨çš„æ‰©æ•£æ¨¡å‹è®¾ç½®ï¼Œç„¶åæˆ‘ä»¬æ¥ä»‹ç»DiTæ‰€è®¾è®¡çš„transformeræ¶æ„ï¼Œè¿™æ‰æ˜¯è¿™ä¸ªå·¥ä½œçš„æ ¸å¿ƒã€‚å…¶å®DiTåŸºæœ¬æ²¿ç”¨äº†ViTçš„è®¾è®¡ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œé¦–å…ˆé‡‡ç”¨ä¸€ä¸ª**patch embeddingæ¥å°†è¾“å…¥è¿›è¡ŒpatchåŒ–**ï¼Œå³å¾—åˆ°ä¸€ç³»åˆ—çš„tokensã€‚å…¶ä¸­patch sizeå±äºä¸€ä¸ªè¶…å‚æ•°ï¼Œå®ƒç›´æ¥å†³å®šäº†tokensçš„æ•°é‡ï¼Œè¿™ä¼šå½±å“æ¨¡å‹çš„è®¡ç®—é‡ã€‚DiTçš„patch sizeå…±é€‰æ‹©äº†ä¸‰ç§è®¾ç½®ï¼šğ‘=2,4,8ã€‚æ³¨æ„tokenåŒ–ä¹‹åï¼Œè¿™é‡Œè¿˜è¦åŠ ä¸Špositional embeddingsï¼Œè¿™é‡Œé‡‡ç”¨éå­¦ä¹ çš„sin-cosineä½ç½®ç¼–ç ã€‚

![Untitled](Diffusion%20model%EF%BC%9ADiT,%20transformer%20only%208a22b30972f343d0befe0f0a373d8387/Untitled%202.png)

å°†è¾“å…¥tokenåŒ–ä¹‹åï¼Œå°±å¯ä»¥åƒViTé‚£æ ·æ¥transformer blocksäº†ã€‚ä½†æ˜¯å¯¹äºæ‰©æ•£æ¨¡å‹æ¥è¯´ï¼Œå¾€å¾€è¿˜éœ€è¦åœ¨ç½‘ç»œä¸­åµŒå…¥é¢å¤–çš„æ¡ä»¶ä¿¡æ¯ï¼Œè¿™é‡Œçš„æ¡ä»¶åŒ…æ‹¬timestepsä»¥åŠç±»åˆ«æ ‡ç­¾ï¼ˆå¦‚æœæ˜¯æ–‡ç”Ÿå›¾å°±æ˜¯æ–‡æœ¬ï¼Œä½†æ˜¯DiTè¿™é‡Œå¹¶æ²¡æœ‰æ¶‰åŠï¼‰ã€‚è¦è¯´æ˜çš„ä¸€ç‚¹æ˜¯ï¼Œæ— è®ºæ˜¯timestepsè¿˜æ˜¯ç±»åˆ«æ ‡ç­¾ï¼Œéƒ½å¯ä»¥é‡‡ç”¨ä¸€ä¸ªembeddingæ¥è¿›è¡Œç¼–ç ã€‚DiTå…±è®¾è®¡äº†å››ç§æ–¹æ¡ˆæ¥å®ç°ä¸¤ä¸ªé¢å¤–embeddingsçš„åµŒå…¥ï¼Œå…·ä½“å¦‚ä¸‹ï¼š

1. **In-context conditioning**ï¼šå°†ä¸¤ä¸ªembeddingsçœ‹æˆä¸¤ä¸ªtokensåˆå¹¶åœ¨è¾“å…¥çš„tokensä¸­ï¼Œè¿™ç§å¤„ç†æ–¹å¼æœ‰ç‚¹ç±»ä¼¼ViTä¸­çš„cls tokenï¼Œå®ç°èµ·æ¥æ¯”è¾ƒç®€å•ï¼Œä¹Ÿä¸åŸºæœ¬ä¸Šä¸é¢å¤–å¼•å…¥è®¡ç®—é‡ã€‚
2. **Cross-attention block**ï¼šå°†ä¸¤ä¸ªembeddingsæ‹¼æ¥æˆä¸€ä¸ªæ•°é‡ä¸º2çš„åºåˆ—ï¼Œç„¶ååœ¨transformer blockä¸­æ’å…¥ä¸€ä¸ªcross attentionï¼Œæ¡ä»¶embeddingsä½œä¸ºcross attentionçš„keyå’Œvalueï¼›è¿™ç§æ–¹å¼ä¹Ÿæ˜¯ç›®å‰æ–‡ç”Ÿå›¾æ¨¡å‹æ‰€é‡‡ç”¨çš„æ–¹å¼ï¼Œå®ƒéœ€è¦é¢å¤–å¼•å…¥15%çš„Gflopsã€‚
3. **Adaptive layer norm (adaLN) block**ï¼šé‡‡ç”¨adaLNï¼Œè¿™é‡Œæ˜¯å°†time embeddingå’Œclass embeddingç›¸åŠ ï¼Œç„¶åæ¥å›å½’scaleå’Œshiftä¸¤ä¸ªå‚æ•°ï¼Œè¿™ç§æ–¹å¼ä¹ŸåŸºæœ¬ä¸å¢åŠ è®¡ç®—é‡ã€‚
4. **adaLN-Zero block**ï¼šé‡‡ç”¨zeroåˆå§‹åŒ–çš„adaLNï¼Œè¿™é‡Œæ˜¯å°†adaLNçš„linearå±‚å‚æ•°åˆå§‹åŒ–ä¸ºzeroï¼Œè¿™æ ·ç½‘ç»œåˆå§‹åŒ–æ—¶transformer blockçš„æ®‹å·®æ¨¡å—å°±æ˜¯ä¸€ä¸ªidentityå‡½æ•°ï¼›å¦å¤–ä¸€ç‚¹æ˜¯ï¼Œè¿™é‡Œé™¤äº†åœ¨LNä¹‹åå›å½’scaleå’Œshiftï¼Œè¿˜åœ¨æ¯ä¸ªæ®‹å·®æ¨¡å—ç»“æŸä¹‹å‰å›å½’ä¸€ä¸ªscaleï¼Œå¦‚ä¸Šå›¾æ‰€ç¤ºã€‚

è®ºæ–‡å¯¹å››ç§æ–¹æ¡ˆè¿›è¡Œäº†å¯¹æ¯”è¯•éªŒï¼Œå‘ç°é‡‡ç”¨**adaLN-Zero**æ•ˆæœæ˜¯æœ€å¥½çš„ï¼Œæ‰€ä»¥DiTé»˜è®¤éƒ½é‡‡ç”¨è¿™ç§æ–¹å¼æ¥åµŒå…¥æ¡ä»¶embeddingsã€‚

![Untitled](Diffusion%20model%EF%BC%9ADiT,%20transformer%20only%208a22b30972f343d0befe0f0a373d8387/Untitled%203.png)

è¿™é‡Œä¹Ÿè´´ä¸€ä¸‹åŸºäº**adaLN-Zero**çš„DiT blockçš„å…·ä½“å®ç°ä»£ç ï¼š

```python
class DiTBlock(nn.Module):
    """
    A DiT block with adaptive layer norm zero (adaLN-Zero) conditioning.
    """
    def __init__(self, hidden_size, num_heads, mlp_ratio=4.0, **block_kwargs):
        super().__init__()
        self.norm1 = nn.LayerNorm(hidden_size, elementwise_affine=False, eps=1e-6)
        self.attn = Attention(hidden_size, num_heads=num_heads, qkv_bias=True, **block_kwargs)
        self.norm2 = nn.LayerNorm(hidden_size, elementwise_affine=False, eps=1e-6)
        mlp_hidden_dim = int(hidden_size * mlp_ratio)
        approx_gelu = lambda: nn.GELU(approximate="tanh")
        self.mlp = Mlp(in_features=hidden_size, hidden_features=mlp_hidden_dim, act_layer=approx_gelu, drop=0)
        self.adaLN_modulation = nn.Sequential(
            nn.SiLU(),
            nn.Linear(hidden_size, 6 * hidden_size, bias=True)
        )

        # zero init
        nn.init.constant_(adaLN_modulation[-1].weight, 0)
        nn.init.constant_(adaLN_modulation[-1].bias, 0)

    def forward(self, x, c):
        shift_msa, scale_msa, gate_msa, shift_mlp, scale_mlp, gate_mlp = self.adaLN_modulation(c).chunk(6, dim=1)
        x = x + gate_msa.unsqueeze(1) * self.attn(modulate(self.norm1(x), shift_msa, scale_msa))
        x = x + gate_mlp.unsqueeze(1) * self.mlp(modulate(self.norm2(x), shift_mlp, scale_mlp))
        return x
```

è™½ç„¶DiTå‘ç°**adaLN-Zero**æ•ˆæœæ˜¯æœ€å¥½çš„ï¼Œä½†æ˜¯è¿™ç§æ–¹å¼åªé€‚åˆè¿™ç§åªæœ‰ç±»åˆ«ä¿¡æ¯çš„ç®€å•æ¡ä»¶åµŒå…¥ï¼Œå› ä¸ºåªéœ€è¦å¼•å…¥ä¸€ä¸ªclass embeddingï¼›ä½†æ˜¯å¯¹äºæ–‡ç”Ÿå›¾æ¥è¯´ï¼Œå…¶æ¡ä»¶å¾€å¾€æ˜¯åºåˆ—çš„text embeddingsï¼Œé‡‡ç”¨cross-attentionæ–¹æ¡ˆå¯èƒ½æ˜¯æ›´åˆé€‚çš„ã€‚ ç”±äºå¯¹è¾“å…¥è¿›è¡Œäº†tokenåŒ–ï¼Œæ‰€ä»¥åœ¨ç½‘ç»œçš„æœ€åè¿˜éœ€è¦ä¸€ä¸ªdecoderæ¥æ¢å¤è¾“å…¥çš„åŸå§‹ç»´åº¦ï¼ŒDiTé‡‡ç”¨ä¸€ä¸ªç®€å•çš„linearå±‚æ¥å®ç°ï¼Œç›´æ¥å°†æ¯ä¸ªtokenæ˜ å°„ä¸ºğ‘Ã—ğ‘Ã—2ğ¶çš„tensorï¼Œç„¶åå†è¿›è¡Œreshapeæ¥å¾—åˆ°å’ŒåŸå§‹è¾“å…¥ç©ºé—´ç»´åº¦ä¸€æ ·çš„è¾“å‡ºï¼Œä½†æ˜¯ç‰¹å¾ç»´åº¦å¤§å°æ˜¯åŸæ¥çš„2å€ï¼Œåˆ†åˆ«ç”¨æ¥é¢„æµ‹å™ªéŸ³å’Œæ–¹å·®ã€‚å…·ä½“å®ç°ä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š

```python
class FinalLayer(nn.Module):
    """
    The final layer of DiT.
    """
    def __init__(self, hidden_size, patch_size, out_channels):
        super().__init__()
        self.norm_final = nn.LayerNorm(hidden_size, elementwise_affine=False, eps=1e-6)
        self.linear = nn.Linear(hidden_size, patch_size * patch_size * out_channels, bias=True)
        self.adaLN_modulation = nn.Sequential(
            nn.SiLU(),
            nn.Linear(hidden_size, 2 * hidden_size, bias=True)
        )
        
     nn.init.constant_(self.adaLN_modulation[-1].weight, 0)
        nn.init.constant_(self.adaLN_modulation[-1].bias, 0)
        nn.init.constant_(self.linear.weight, 0)
        nn.init.constant_(self.linear.bias, 0)

    def forward(self, x, c):
        shift, scale = self.adaLN_modulation(c).chunk(2, dim=1)
        x = modulate(self.norm_final(x), shift, scale)
        x = self.linear(x)
        return x
```

åœ¨å…·ä½“æ€§èƒ½ä¸Šï¼Œæœ€å¤§çš„æ¨¡å‹DiT-XL/2é‡‡ç”¨classifier free guidanceå¯ä»¥åœ¨class-conditional image generation on ImageNet 256Ã—256ä»»åŠ¡ä¸Šå®ç°å½“æ—¶çš„sotaã€‚

![Untitled](Diffusion%20model%EF%BC%9ADiT,%20transformer%20only%208a22b30972f343d0befe0f0a373d8387/Untitled%204.png)

è™½ç„¶DiTçœ‹èµ·æ¥ä¸é”™ï¼Œä½†æ˜¯åªåœ¨ImageNetä¸Šç”Ÿæˆåšäº†å®éªŒï¼Œå¹¶æ²¡æœ‰æ‰©å±•åˆ°å¤§è§„æ¨¡çš„æ–‡ç”Ÿå›¾æ¨¡å‹ã€‚è€Œä¸”åœ¨DiTä¹‹å‰ï¼Œå…¶å®ä¹Ÿæœ‰åŸºäºtransformeræ¶æ„çš„æ‰©æ•£æ¨¡å‹ç ”ç©¶å·¥ä½œï¼Œæ¯”å¦‚[U-ViT](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2209.12152)ï¼Œç›®å‰ä¹Ÿå·²ç»æœ‰å°†transformeråº”ç”¨åœ¨å¤§è§„æ¨¡æ–‡ç”Ÿå›¾ï¼ˆåŸºäºæ‰©æ•£æ¨¡å‹ï¼‰çš„å·¥ä½œï¼Œæ¯”å¦‚[UniDiffuser](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2303.06555)ï¼Œä½†æ˜¯å…¶å®éƒ½æ²¡æœ‰å—åˆ°å¤ªå¤§çš„å…³æ³¨ã€‚ç›®å‰ä¸»æµçš„æ–‡ç”Ÿå›¾æ¨¡å‹è¿˜æ˜¯é‡‡ç”¨åŸºäºUNetï¼Œ**UNetæœ¬èº«ä¹Ÿæ··åˆäº†å·ç§¯å’Œattentionï¼Œå®ƒçš„ä¼˜åŠ¿ä¸€æ–¹é¢æ˜¯é«˜æ•ˆï¼Œå¦å¤–ä¸€æ–¹é¢æ˜¯ä¸éœ€è¦ä½ç½®ç¼–ç æ¯”è¾ƒå®¹æ˜“å®ç°å˜å°ºåº¦çš„ç”Ÿæˆ**ï¼Œè¿™äº›å¯¹å…·ä½“è½åœ°åº”ç”¨éƒ½æ˜¯æ¯”è¾ƒé‡è¦çš„ã€‚

### **å‚è€ƒ**

- [Scalable Diffusion Models with Transformers](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2212.09748)
- [https://github.com/facebookresearch/DiT](https://link.zhihu.com/?target=https%3A//github.com/facebookresearch/DiT)
- [High-Resolution Image Synthesis with Latent Diffusion Models](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2112.10752)
- [Improved Denoising Diffusion Probabilistic Models](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2102.09672)