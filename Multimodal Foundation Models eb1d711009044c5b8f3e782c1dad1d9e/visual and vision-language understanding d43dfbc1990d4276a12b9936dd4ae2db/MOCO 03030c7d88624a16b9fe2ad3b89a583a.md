# MOCO

# **Momentum Contrast for Unsupervised Visual Representation Learning**

[](https://arxiv.org/pdf/1911.05722.pdf)

![Untitled](MOCO%2003030c7d88624a16b9fe2ad3b89a583a/Untitled.png)

MOCO说明无监督学习是王道。

只需定义找一个代理任务（instance discrimination），正负样本即可。

正样本定义：同一张图两个tranform，同一个句子不同的dropout，同一个物体的不同角度图像，同一个物体不同模式（深度图vsRGB）

# Abstract

We present **Momentum Contrast (MoCo)** for unsupervised visual representation learning. From a perspective on contrastive learning [29] as dictionary look-up, we build a **dynamic dictionary** **with a queue and a moving-averaged encoder**. This enables building **a large and consistent dictionary** on-the-fly that facilitates contrastive unsupervised learning. MoCo provides competitive results under the common linear protocol on ImageNet classification. More importantly, the representations learned by **MoCo transfer well to downstream tasks**. MoCo can outperform its super- vised pre-training counterpart in 7 detection/segmentation tasks on PASCAL VOC, COCO, and other datasets, some- times surpassing it by large margins. This suggests that the gap between unsupervised and supervised representa- tion learning has been largely closed in many vision tasks

# Introduction

Computer vision, in contrast, further concerns **dictionary building**, as the raw signal is
in a **continuous, high-dimensional space** and is not structured for human communication.

### Dynamic Dictionary

**building dynamic dictionaries：**The “keys” (tokens) in the dictionary are sampled from data (e.g., images or patches) and are represented by an **encoder** network. Unsupervised learning trains encoders to perform dictionary look-up: an encoded “query” should be similar to its matching key and dissimilar to others. Learning is formulated as minimizing a contrastive loss

![Untitled](MOCO%2003030c7d88624a16b9fe2ad3b89a583a/Untitled%201.png)

hypothesize that it is desirable to build **dictionaries** that are**: (i) large and (ii) consistent** as they evolve during training. Intuitively,

Momentum Contrast **(MoCo) as a way of building large and consistent dictionaries** for unsupervised learning with a contrastive loss (Figure 1).

![Untitled](MOCO%2003030c7d88624a16b9fe2ad3b89a583a/Untitled%202.png)

![Untitled](MOCO%2003030c7d88624a16b9fe2ad3b89a583a/Untitled%203.png)

momentum encoder is initialized with encoder. Then update with momentum. m is quite large for slowly update

# Method

### Contrastive Learning as Dictionary Look-up Contrastive

Contrastive learning [29], and its recent developments, can be thought of as training an encoder for a dictionary look-up task, as described next. Consider an encoded query q and a set of encoded samples {k0, k1, k2, ...} that are the keys of a dictionary. Assume that there is a single key (denoted as k+) in the dictionary that q matches. A contrastive loss [29] is a function whose value is low when q is similar to its positive key k+ and dissimilar to all other keys (considered negative keys for q). With similarity measured by dot product, a form of a contrastive loss function, called **InfoNCE** [46], is considered in this paper

![Untitled](MOCO%2003030c7d88624a16b9fe2ad3b89a583a/Untitled%204.png)

多类问题的crossEntroy：

![Untitled](MOCO%2003030c7d88624a16b9fe2ad3b89a583a/Untitled%205.png)

NCE：超级多类的分类问题，变成一系列二分类问题，并且取其中一部分而不是所有样本做近似。进而可以继续用softmax做计算。

InfoNCE：把NCE中的二分类变回多类分类问题。上图黄色的crossentroyloss公式中k表示类别数量。InfoNCE公式中的K指的是负样本个数。

### Momentum contrast

**Dictionary as a queue**. At the core of our approach is maintaining the dictionary as a queue of data samples. This allows us to reuse the encoded keys from the immediate pre- ceding mini-batches. The introduction of a queue decouples the dictionary size from the mini-batch size. 

### Momentum update

Using a queue can make the dictio- nary large, but it also makes it intractable to update the key encoder by back-propagation (the gradient should propagate to all samples in the queue). 

![Untitled](MOCO%2003030c7d88624a16b9fe2ad3b89a583a/Untitled%206.png)

The momentum update in Eqn.(2) make**s θk evolve more smoothly than θq.** As a result, though the keys in the queue are encoded by different encoders (in different mini-batches), the dif- ference among these encoders can be made small. In experiments, **a relatively large** momentum (e.g., m = 0.999, our default) **works much better** than a smaller value (e.g., m = 0.9), suggesting that a **slowly evolving key encoder is a core** to making use of a queue. 

### Relations to previous mechanisms.

![Untitled](MOCO%2003030c7d88624a16b9fe2ad3b89a583a/Untitled%207.png)

The **end-to-end** update by back-propagation is a natural mechanism (e.g., [29, 46, 36, 63, 2, 35], Figure 2a). It uses **samples in the current mini-batch as the dictionary**, so the keys are consistently encoded (by the same set of encoder parameters). But the **dictionary size is coupled with the mini-batch size**, limited by the GPU memory size. It is also challenged by **large mini-batch optimization**

Another mechanism is the **memory bank** approach proposed by [61] (Figure 2b). A memory bank consists of the representations of all samples in the dataset. The dictionary for each mini-batch is **randomly sampled from the memory bank with no back-propagation,** so it can support a large dictionary size. However, the representation of a sample in the memory bank was updated when it was **last seen,** so the sampled keys are essentially about the encoders at multiple different steps all over the past epoch and thus are **less consistent**.

### Pretext Task

Instance discrimination task

**Algorithm 1 Pseudocode of MoCo in a PyTorch-like style**

![Untitled](MOCO%2003030c7d88624a16b9fe2ad3b89a583a/Untitled%208.png)

**Technical details**. We adopt a **ResNet** [33] as the encoder, whose last fully-connected layer (after global average pool- ing) has a fixed-dimensional output (128-D [61]). This out- put vector is normalized by its L2-norm [61]. This is the representation of the query or key. The temperature τ in Eqn.(1) is set as 0.07 [61]. The data augmentation setting follows [61]: a 224×224-pixel crop is taken from a ran- domly resized image, and then undergoes random color jit- tering, random horizontal flip, and random grayscale con- version, all available in PyTorch’s torchvision package.