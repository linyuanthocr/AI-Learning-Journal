# Diffusion model â€” SDXL

[arxiv.org](https://arxiv.org/pdf/2307.01952)

[zhuanlan.zhihu.com](https://zhuanlan.zhihu.com/p/642496862)

ä¹‹å‰çš„æ–‡ç« [æ–‡ç”Ÿå›¾æ¨¡å‹ä¹‹Stable Diffusion](https://zhuanlan.zhihu.com/p/617134893)å·²ç»ä»‹ç»äº†æ¯”è¾ƒç«çš„æ–‡ç”Ÿå›¾æ¨¡å‹Stable Diffusionï¼Œè¿‘æœŸStability AIåˆå‘å¸ƒäº†æ–°çš„å‡çº§ç‰ˆæœ¬[SDXL](https://link.zhihu.com/?target=https%3A//stability.ai/blog/sdxl-09-stable-diffusion)ã€‚ç›®å‰SDXLçš„ä»£ç ã€æ¨¡å‹ä»¥åŠæŠ€æœ¯æŠ¥å‘Šå·²ç»å…¨éƒ¨å¼€æºï¼š

- å®˜æ–¹ä»£ç ï¼š[https://github.com/Stability-AI/generative-models](https://link.zhihu.com/?target=https%3A//github.com/Stability-AI/generative-models)
- æ¨¡å‹æƒé‡ï¼š[https://huggingface.co/stabilityai/stable-diffusion-xl-base-0.9](https://link.zhihu.com/?target=https%3A//huggingface.co/stabilityai/stable-diffusion-xl-base-0.9)
- æŠ€æœ¯æŠ¥å‘Šï¼š[SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2307.01952)

è€Œä¸”SDXLä¹Ÿå·²ç»é›†æˆåœ¨äº†huggingfaceçš„diffusersåº“ä¸­ï¼š[diffusers/pipelines/stable_diffusion_xl](https://link.zhihu.com/?target=https%3A//github.com/huggingface/diffusers/tree/main/src/diffusers/pipelines/stable_diffusion_xl)ã€‚SDXLå’Œä¹‹å‰çš„ç‰ˆæœ¬ä¸€æ ·ä¹Ÿæ˜¯é‡‡ç”¨latent diffusionæ¶æ„ï¼Œä½†SDXLç›¸æ¯”ä¹‹å‰çš„ç‰ˆæœ¬SD 1.xå’ŒSD 2.xæœ‰æ˜æ˜¾çš„æå‡ï¼Œä¸‹é¢æ˜¯SDXLå’Œä¹‹å‰SD 1.5å’ŒSD 2.1çš„ä¸€äº›ç›´è§‚å¯¹æ¯”å›¾ï¼š

![Untitled](Diffusion%20model%20%E2%80%94%20SDXL%20034fb5c11e2b4b82b3e5931c50a86a6a/Untitled.png)

å¯ä»¥çœ‹åˆ°SDXLæ— è®ºæ˜¯åœ¨æ–‡æœ¬ç†è§£è¿˜æ˜¯åœ¨ç”Ÿæˆå›¾åƒè´¨é‡ä¸Šï¼Œç›¸æ¯”ä¹‹å‰çš„ç‰ˆæœ¬å‡æœ‰æ¯”è¾ƒå¤§çš„æå‡ã€‚SDXLæ€§èƒ½çš„æå‡ä¸»è¦å½’åŠŸäºä»¥ä¸‹å‡ ç‚¹çš„æ”¹è¿›ï¼š

- **SDXLçš„æ¨¡å‹å‚æ•°å¢å¤§ä¸º2.3Bï¼Œè¿™å‡ ä¹ä¸ŠåŸæ¥æ¨¡å‹çš„3å€ï¼Œè€Œä¸”SDXLé‡‡ç”¨äº†ä¸¤ä¸ªCLIP text encoderæ¥ç¼–ç æ–‡æœ¬ç‰¹å¾ï¼›**
- **SDXLé‡‡ç”¨äº†é¢å¤–çš„æ¡ä»¶æ³¨å…¥æ¥æ”¹å–„è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ•°æ®å¤„ç†é—®é¢˜ï¼Œè€Œä¸”æœ€åä¹Ÿé‡‡ç”¨äº†å¤šå°ºåº¦çš„å¾®è°ƒï¼›**
- **SDXLçº§è”äº†ä¸€ä¸ªç»†åŒ–æ¨¡å‹æ¥æå‡å›¾åƒçš„ç”Ÿæˆè´¨é‡ã€‚**

è¿™ç¯‡æ–‡ç« æˆ‘ä»¬å°†ç»“åˆSDXLçš„ä»£ç æ¥å…·ä½“è®²è§£ä¸Šè¿°çš„æ”¹è¿›æŠ€å·§ã€‚

### **æ¨¡å‹æ¶æ„ä¸Šçš„ä¼˜åŒ–**

SDXLå’Œä¹‹å‰çš„ç‰ˆæœ¬ä¹Ÿæ˜¯åŸºäº**latent diffusionæ¶æ„**ï¼Œå¯¹äºlatent diffusionï¼Œé¦–å…ˆä¼šé‡‡ç”¨ä¸€ä¸ªautoencoderæ¨¡å‹æ¥å›¾åƒå‹ç¼©ä¸ºlatentï¼Œç„¶åæ‰©æ•£æ¨¡å‹ç”¨æ¥ç”Ÿæˆlatentï¼Œç”Ÿæˆçš„latentå¯ä»¥é€šè¿‡autoencoderçš„decoderæ¥é‡å»ºå‡ºå›¾åƒã€‚SDXLçš„autoencoderä¾ç„¶é‡‡ç”¨KL-f8ï¼Œä½†æ˜¯å¹¶æ²¡æœ‰é‡‡ç”¨ä¹‹å‰çš„autoencoderï¼Œè€Œæ˜¯**åŸºäºåŒæ ·çš„æ¶æ„é‡‡ç”¨äº†æ›´å¤§çš„batch sizeï¼ˆ256 vs 9ï¼‰é‡æ–°è®­ç»ƒï¼ŒåŒæ—¶é‡‡ç”¨äº†EMA**ã€‚é‡æ–°è®­ç»ƒçš„VAEæ¨¡å‹ï¼ˆå°½ç®¡å’ŒVAEæœ‰åŒºåˆ«ï¼Œå¤§å®¶å¾€å¾€ä¹ æƒ¯ç§°VAEï¼‰ç›¸æ¯”ä¹‹å‰çš„æ¨¡å‹ï¼Œå…¶é‡å»ºæ€§èƒ½æœ‰ä¸€å®šçš„æå‡ï¼Œæ€§èƒ½å¯¹æ¯”å¦‚ä¸‹æ‰€ç¤ºï¼š

![Untitled](Diffusion%20model%20%E2%80%94%20SDXL%20034fb5c11e2b4b82b3e5931c50a86a6a/Untitled%201.png)

è¿™é‡Œè¦æ³¨æ„çš„æ˜¯ä¸Šè¡¨ä¸­çš„ä¸‰ä¸ªVAEæ¨¡å‹å…¶å®æ¨¡å‹ç»“æ„æ˜¯å®Œå…¨ä¸€æ ·ï¼Œå…¶ä¸­SD-VAE 2.xåªæ˜¯åœ¨SD-VAE 1.xçš„åŸºç¡€ä¸Šé‡æ–°å¾®è°ƒäº†decoderéƒ¨åˆ†ï¼Œä½†æ˜¯encoderæƒé‡æ˜¯ç›¸åŒçš„ï¼Œæ‰€ä»¥ä¸¤è€…çš„latentåˆ†å¸ƒæ˜¯ä¸€æ ·çš„ï¼Œä¸¤ä¸ªVAEæ¨¡å‹æ˜¯éƒ½å¯ä»¥ç”¨åœ¨SD 1.xå’ŒSD 2.xä¸Šçš„ã€‚ä½†æ˜¯SDXL-VAEæ˜¯å®Œå…¨é‡æ–°è®­ç»ƒçš„ï¼Œå®ƒçš„latentåˆ†å¸ƒå‘ç”Ÿäº†æ”¹å˜ï¼Œä½ **ä¸å¯ä»¥å°†SDXL-VAEåº”ç”¨åœ¨SD 1.xå’ŒSD 2.xä¸Š**ã€‚åœ¨å°†latenté€å…¥æ‰©æ•£æ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬è¦å¯¹latentè¿›è¡Œç¼©æ”¾æ¥ä½¿å¾—latentçš„æ ‡å‡†å·®å°½é‡ä¸º1ï¼Œç”±äºæƒé‡å‘ç”Ÿäº†æ”¹å˜ï¼Œæ‰€ä»¥**SDXL-VAEçš„ç¼©æ”¾ç³»æ•°ä¹Ÿå’Œä¹‹å‰ä¸åŒï¼Œä¹‹å‰çš„ç‰ˆæœ¬é‡‡ç”¨çš„ç¼©æ”¾ç³»æ•°ä¸º0.18215ï¼Œè€ŒSDXL-VAEçš„ç¼©æ”¾ç³»æ•°ä¸º0.13025**ã€‚SDXL-VAEçš„æƒé‡ä¹Ÿå·²ç»å•ç‹¬ä¸Šä¼ åˆ°huggingfaceä¸Šï¼ˆ[https://huggingface.co/stabilityai/sdxl-vae](https://link.zhihu.com/?target=https%3A//huggingface.co/stabilityai/sdxl-vae)ï¼‰ï¼Œä¸€ä¸ªè¦æ³¨æ„çš„ç‚¹æ˜¯SDXL-VAEé‡‡ç”¨float16ä¼šå‡ºç°æº¢å‡ºï¼ˆå…·ä½“è§[è¿™é‡Œ](https://link.zhihu.com/?target=https%3A//github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py%23L786)ï¼‰ï¼Œ**å¿…é¡»è¦ä½¿ç”¨float32æ¥è¿›è¡Œæ¨ç†**ï¼Œä½†æ˜¯ä¹‹å‰çš„ç‰ˆæœ¬ä½¿ç”¨float16å¤§éƒ¨åˆ†æƒ…å†µéƒ½æ˜¯å¯ä»¥çš„ã€‚VAEçš„é‡å»ºèƒ½åŠ›å¯¹SDç”Ÿæˆçš„å›¾åƒè´¨é‡è¿˜æ˜¯æ¯”è¾ƒé‡è¦çš„ï¼ŒSDç”Ÿæˆçš„å›¾åƒå®¹æ˜“å‡ºç°å°ç‰©ä½“ç•¸å˜ï¼Œè¿™å¾€å¾€æ˜¯ç”±äºVAEå¯¼è‡´çš„ï¼ŒSDXL-VAEç›¸æ¯”SD-VAE 2.xçš„æå‡å…¶å®æ¯”è¾ƒå¾®å¼±ï¼Œæ‰€ä»¥ä¹Ÿä¸ä¼šå¤§å¹…åº¦ç¼“è§£ä¹‹å‰çš„ç•¸å˜é—®é¢˜ã€‚

SDXLç›¸æ¯”ä¹‹å‰çš„ç‰ˆæœ¬ï¼Œä¸€ä¸ªæœ€å¤§çš„å˜åŒ–é‡‡ç”¨äº†æ›´å¤§çš„UNetï¼Œä¸‹è¡¨ä¸ºSDXLå’Œä¹‹å‰çš„SDçš„å…·ä½“å¯¹æ¯”ï¼Œä¹‹å‰çš„SDçš„UNetå‚æ•°é‡å°äº1Bï¼Œä½†æ˜¯**SDXLçš„UNetå‚æ•°é‡è¾¾åˆ°äº†2.6Bï¼Œæ¯”ä¹‹å‰çš„ç‰ˆæœ¬è¶³è¶³å¤§äº†3å€**ã€‚

![Untitled](Diffusion%20model%20%E2%80%94%20SDXL%20034fb5c11e2b4b82b3e5931c50a86a6a/Untitled%202.png)

ä¸‹é¢æˆ‘ä»¬æ¥é‡ç‚¹çœ‹ä¸€ä¸‹SDXLæ˜¯å¦‚ä½•æ‰©å¢UNetå‚æ•°çš„ï¼ŒSDXLçš„UNetæ¨¡å‹ç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![Untitled](Diffusion%20model%20%E2%80%94%20SDXL%20034fb5c11e2b4b82b3e5931c50a86a6a/Untitled%203.png)

ç›¸æ¯”ä¹‹å‰çš„SDï¼ŒSDXLçš„ç¬¬ä¸€ä¸ªstageé‡‡ç”¨çš„æ˜¯æ™®é€šçš„DownBlock2Dï¼Œè€Œä¸æ˜¯é‡‡ç”¨åŸºäºattentionçš„CrossAttnDownBlock2Dï¼Œè¿™ä¸ªä¸»è¦æ˜¯ä¸ºäº†è®¡ç®—æ•ˆç‡ï¼Œå› ä¸ºSDXLæœ€åæ˜¯ç›´æ¥ç”Ÿæˆ1024x1024åˆ†è¾¨ç‡çš„å›¾åƒï¼Œå¯¹åº”çš„latentå¤§å°ä¸º128x128x4ï¼Œå¦‚æœç¬¬ä¸€ä¸ªstageå°±ä½¿ç”¨äº†attentionï¼ˆåŒ…å«self-attentionï¼‰ï¼Œæ‰€éœ€è¦çš„æ˜¾å­˜å’Œè®¡ç®—é‡éƒ½æ˜¯æ¯”è¾ƒå¤§çš„ã€‚å¦å¤–ä¸€ä¸ªå˜åŒ–æ˜¯SDXLåªç”¨äº†3ä¸ªstageï¼Œè¿™æ„å‘³ç€åªè¿›è¡Œäº†ä¸¤æ¬¡2xä¸‹é‡‡æ ·ï¼Œè€Œä¹‹å‰çš„SDä½¿ç”¨4ä¸ªstageï¼ŒåŒ…å«3ä¸ª2xä¸‹é‡‡æ ·ã€‚SDXLçš„ç½‘ç»œå®½åº¦ï¼ˆè¿™é‡Œçš„ç½‘ç»œå®½åº¦æ˜¯æŒ‡çš„æ˜¯ç‰¹å¾channelsï¼‰ç›¸æ¯”ä¹‹å‰çš„ç‰ˆæœ¬å¹¶æ²¡æœ‰æ”¹å˜ï¼Œ3ä¸ªstageçš„ç‰¹å¾channelsåˆ†åˆ«æ˜¯320ã€640å’Œ1280ã€‚**SDXLå‚æ•°é‡çš„å¢åŠ ä¸»è¦æ˜¯ä½¿ç”¨äº†æ›´å¤šçš„transformer blocks**ï¼Œåœ¨ä¹‹å‰çš„ç‰ˆæœ¬ï¼Œæ¯ä¸ªåŒ…å«attentionçš„blockåªä½¿ç”¨ä¸€ä¸ªtransformer blockï¼ˆself-attention -> cross-attention -> ffnï¼‰ï¼Œä½†æ˜¯SDXLä¸­stage2å’Œstage3çš„ä¸¤ä¸ªCrossAttnDownBlock2Dæ¨¡å—ä¸­çš„transformer blockæ•°é‡åˆ†åˆ«è®¾ç½®ä¸º2å’Œ10ï¼Œå¹¶ä¸”ä¸­é—´çš„MidBlock2DCrossAttnçš„transformer blocksæ•°é‡ä¹Ÿè®¾ç½®ä¸º10ï¼ˆå’Œæœ€åä¸€ä¸ªstageä¿æŒä¸€æ ·ï¼‰ã€‚å¯ä»¥çœ‹åˆ°SDXLçš„UNetåœ¨ç©ºé—´ç»´åº¦æœ€å°çš„ç‰¹å¾ä¸Šä½¿ç”¨æ•°é‡è¾ƒå¤šçš„transformer blockï¼Œè¿™æ˜¯è®¡ç®—æ•ˆç‡æœ€é«˜çš„ã€‚

SDXLçš„å¦å¤–ä¸€ä¸ªå˜åŠ¨æ˜¯text encoderï¼ŒSD 1.xé‡‡ç”¨çš„text encoderæ˜¯123Mçš„OpenAI CLIP ViT-L/14ï¼Œè€ŒSD 2.xå°†text encoderå‡çº§ä¸º354Mçš„OpenCLIP ViT-H/14ã€‚SDXLæ›´è¿›ä¸€æ­¥ï¼Œä¸ä»…é‡‡ç”¨äº†æ›´å¤§çš„[OpenCLIP ViT-bigG](https://link.zhihu.com/?target=https%3A//laion.ai/blog/giant-openclip/)ï¼ˆå‚æ•°é‡ä¸º694Mï¼‰ï¼Œè€Œä¸”åŒæ—¶ä¹Ÿç”¨äº†OpenAI CLIP ViT-L/14ï¼Œè¿™é‡Œæ˜¯åˆ†åˆ«æå–ä¸¤ä¸ªtext encoderçš„å€’æ•°ç¬¬äºŒå±‚ç‰¹å¾ï¼Œå…¶ä¸­OpenCLIP ViT-bigGçš„ç‰¹å¾ç»´åº¦ä¸º1280ï¼Œè€ŒCLIP ViT-L/14çš„ç‰¹å¾ç»´åº¦æ˜¯768ï¼Œä¸¤ä¸ªç‰¹å¾concatåœ¨ä¸€èµ·æ€»çš„ç‰¹å¾ç»´åº¦å¤§å°æ˜¯2048ï¼Œè¿™ä¹Ÿå°±æ˜¯SDXLçš„context dimã€‚OpenCLIP ViT-bigGç›¸æ¯”OpenCLIP ViT-H/14ï¼Œåœ¨æ€§èƒ½ä¸Šæœ‰ä¸€å®šçš„æå‡ï¼Œå…¶ä¸­åœ¨ImageNetä¸Šzero-shotæ€§èƒ½ä¸º80.1%ã€‚å¼ºå¤§çš„text encoderå¯¹äºæ–‡ç”Ÿå›¾æ¨¡å‹çš„æ–‡æœ¬ç†è§£èƒ½åŠ›æ˜¯è‡³å…³é‡è¦çš„ã€‚

![Untitled](Diffusion%20model%20%E2%80%94%20SDXL%20034fb5c11e2b4b82b3e5931c50a86a6a/Untitled%204.png)

è¿™é‡Œæœ‰ä¸€ä¸ªå¤„ç†ç»†èŠ‚æ˜¯æå–äº†OpenCLIP ViT-bigGçš„pooled text embeddingï¼ˆç”¨äºCLIPå¯¹æ¯”å­¦ä¹ æ‰€ä½¿ç”¨çš„ç‰¹å¾ï¼‰ï¼Œå°†å…¶æ˜ å°„åˆ°time embeddingçš„ç»´åº¦å¹¶ä¸ä¹‹ç›¸åŠ ã€‚è¿™ç§ç‰¹å¾åµŒå…¥æ–¹å¼åœ¨å¼ºåº¦ä¸Šå¹¶ä¸å¦‚cross attentionï¼Œåªæ˜¯ä½œä¸ºä¸€ç§è¾…åŠ©ã€‚

ç»è¿‡ä¸Šè¿°è°ƒæ•´ï¼ŒSDXLçš„UNetæ€»å‚æ•°é‡ä¸º2.6Bã€‚SDXLåªæ˜¯UNetå˜åŒ–äº†ï¼Œè€Œæ‰©æ•£æ¨¡å‹çš„è®¾ç½®æ˜¯å’ŒåŸæ¥çš„SDä¸€æ ·ï¼Œéƒ½é‡‡ç”¨1000æ­¥çš„DDPMï¼Œnoise schedulerä¹Ÿä¿æŒæ²¡åŠ¨ï¼Œè®­ç»ƒæŸå¤±æ˜¯é‡‡ç”¨åŸºäºé¢„æµ‹noiseçš„ğ¿simpleã€‚

### **é¢å¤–çš„æ¡ä»¶æ³¨å…¥**

SDXLçš„ç¬¬äºŒä¸ªä¼˜åŒ–ç‚¹é‡‡ç”¨äº†é¢å¤–çš„æ¡ä»¶æ³¨å…¥æ¥è§£å†³è®­ç»ƒè¿‡ç¨‹ä¸­æ•°æ®å¤„ç†é—®é¢˜ï¼Œè¿™é‡ŒåŒ…æ‹¬ä¸¤ç§æ¡ä»¶æ³¨å…¥æ–¹å¼ï¼Œå®ƒä»¬åˆ†åˆ«è§£å†³è®­ç»ƒè¿‡ç¨‹ä¸­**æ•°æ®åˆ©ç”¨æ•ˆç‡å’Œå›¾åƒè£å‰ªé—®é¢˜**ã€‚

é¦–å…ˆæˆ‘ä»¬æ¥çœ‹ç¬¬ä¸€ä¸ªé—®é¢˜ï¼ŒSDçš„è®­ç»ƒå¾€å¾€æ˜¯å…ˆåœ¨256x256ä¸Šé¢„è®­ç»ƒï¼Œç„¶ååœ¨512x512ä¸Šç»§ç»­è®­ç»ƒã€‚å½“ä½¿ç”¨256x256å°ºå¯¸è®­ç»ƒæ—¶ï¼Œè¦è¿‡æ»¤æ‰é‚£äº›å®½åº¦å’Œé«˜åº¦å°äº256çš„å›¾åƒï¼Œé‡‡ç”¨512x512å°ºå¯¸è®­ç»ƒæ—¶ä¹ŸåŒæ ·åªç”¨512x512å°ºå¯¸ä»¥ä¸Šçš„å›¾åƒã€‚ç”±äºéœ€è¦è¿‡æ»¤æ•°æ®ï¼Œè¿™å°±å¯¼è‡´å®é™…å¯ç”¨çš„è®­ç»ƒæ ·æœ¬å‡å°‘äº†ï¼Œè¦çŸ¥é“è®­ç»ƒæ•°æ®é‡å¯¹å¤§æ¨¡å‹çš„æ€§èƒ½å½±å“æ˜¯æ¯”è¾ƒå¤§ã€‚ä¸‹å›¾å±•ç¤ºäº†SDXLé¢„è®­ç»ƒæ•°æ®çš„å›¾åƒå°ºå¯¸åˆ†å¸ƒï¼Œå¯ä»¥çœ‹åˆ°å¦‚æœè¦è¿‡æ»¤256ä¸€ä¸‹çš„å›¾åƒï¼Œå°±å…¶å®ä¸¢æ‰äº†39%çš„è®­ç»ƒæ ·æœ¬ã€‚

ä¸€ç§ç›´æ¥çš„è§£å†³æ–¹æ¡ˆæ˜¯é‡‡ç”¨ä¸€ä¸ªè¶…åˆ†æ¨¡å‹å…ˆå¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œä½†æ˜¯ç›®å‰è¶…åˆ†æ¨¡å‹å¹¶ä¸æ˜¯å®Œç¾çš„ï¼Œè¿˜æ˜¯ä¼šå‡ºç°ä¸€äº›artifactsï¼ˆå¯¹äºpixel diffusionæ¨¡å‹æ¯”å¦‚Imagenï¼Œå¾€å¾€æ˜¯é‡‡ç”¨çº§è”çš„æ¨¡å‹ï¼Œ64x64çš„baseæ¨¡å‹åŠ ä¸Šä¸¤ä¸ªè¶…åˆ†æ¨¡å‹ï¼Œå…¶ä¸­baseæ¨¡å‹çš„æ•°æ®åˆ©ç”¨æ•ˆç‡æ˜¯æ¯”è¾ƒé«˜çš„ï¼Œä½†æ˜¯å¯èƒ½çš„é£é™©æ˜¯è¶…åˆ†æ¨¡å‹ä¹Ÿå¯èƒ½ä¼šå‡ºç°artifactsï¼‰ã€‚SDXLæå‡ºäº†ä¸€ç§ç®€å•çš„æ–¹æ¡ˆæ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œé‚£å°±æ˜¯**å°†å›¾åƒçš„åŸå§‹å°ºå¯¸ï¼ˆwidthå’Œheightï¼‰ä½œä¸ºæ¡ä»¶åµŒå…¥UNetæ¨¡å‹ä¸­ï¼Œè¿™ç›¸å½“äºè®©æ¨¡å‹å­¦åˆ°äº†å›¾åƒåˆ†è¾¨ç‡å‚æ•°ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä¸è¿‡æ»¤æ•°æ®ç›´æ¥resizeå›¾åƒï¼Œåœ¨æ¨ç†æ—¶ï¼Œæˆ‘ä»¬åªéœ€è¦é€å…¥ç›®æ ‡åˆ†è¾¨ç‡è€Œä¿è¯ç”Ÿæˆçš„å›¾åƒè´¨é‡ã€‚**å›¾åƒåŸå§‹å°ºå¯¸åµŒå…¥çš„å®ç°ä¹Ÿæ¯”è¾ƒç®€å•ï¼Œå’Œtimestepsçš„åµŒå…¥ä¸€æ ·ï¼Œå…ˆå°†widthå’Œheightç”¨å‚…ç«‹å¶ç‰¹å¾ç¼–ç è¿›è¡Œç¼–ç ï¼Œç„¶åå°†ç‰¹å¾concatåœ¨ä¸€èµ·åŠ åœ¨time embeddingä¸Šã€‚ä¸‹å›¾å±•ç¤ºäº†é‡‡ç”¨è¿™ç§æ–¹æ¡ˆå¾—åˆ°çš„512x512æ¨¡å‹å½“é€å…¥ä¸åŒçš„sizeæ—¶çš„ç”Ÿæˆå›¾åƒå¯¹æ¯”ï¼Œå¯ä»¥çœ‹åˆ°æ¨¡å‹å·²ç»å­¦åˆ°äº†è¯†åˆ«å›¾åƒåˆ†è¾¨ç‡ï¼Œå½“è¾“å…¥ä½åˆ†è¾¨ç‡æ—¶ï¼Œç”Ÿæˆçš„å›¾åƒæ¯”è¾ƒæ¨¡ç³Šï¼Œä½†æ˜¯å½“æå‡sizeæ—¶ï¼Œå›¾åƒè´¨é‡é€æ¸æå‡ã€‚

![Untitled](Diffusion%20model%20%E2%80%94%20SDXL%20034fb5c11e2b4b82b3e5931c50a86a6a/Untitled%205.png)

ç¬¬äºŒä¸ªé—®é¢˜æ˜¯è®­ç»ƒè¿‡ç¨‹ä¸­çš„**å›¾åƒè£å‰ª**é—®é¢˜ï¼Œç›®å‰æ–‡ç”Ÿå›¾æ¨¡å‹é¢„è®­ç»ƒå¾€å¾€é‡‡ç”¨å›ºå®šå›¾åƒå°ºå¯¸ï¼Œè¿™å°±éœ€è¦å¯¹åŸå§‹å›¾åƒè¿›è¡Œé¢„å¤„ç†ï¼Œè¿™ä¸ªå¤„ç†æµç¨‹ä¸€èˆ¬æ˜¯å…ˆå°†å›¾åƒçš„æœ€çŸ­è¾¹resizeåˆ°ç›®æ ‡å°ºå¯¸ï¼Œç„¶åæ²¿ç€å›¾åƒçš„æœ€é•¿è¾¹è¿›è¡Œè£å‰ªï¼ˆrandom cropæˆ–è€…center cropï¼‰ã€‚ä½†æ˜¯å›¾åƒè£å‰ªå¾€å¾€ä¼šå¯¼è‡´å›¾åƒå‡ºç°ç¼ºå¤±é—®é¢˜ï¼Œæ¯”å¦‚ä¸‹å›¾é‡‡ç”¨center cropå¯¼è‡´äººç‰©çš„å¤´å’Œè„šç¼ºå¤±äº†ï¼Œè¿™ä¹Ÿç›´æ¥å¯¼è‡´æ¨¡å‹å®¹æ˜“ç”Ÿæˆç¼ºæŸçš„å›¾åƒã€‚

ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œ**SDXLä¹Ÿå°†è®­ç»ƒè¿‡ç¨‹ä¸­è£å‰ªçš„å·¦ä¸Šå®šç‚¹åæ ‡ä½œä¸ºé¢å¤–çš„æ¡ä»¶æ³¨å…¥åˆ°UNetä¸­**ï¼Œè¿™ä¸ªæ³¨å…¥æ–¹å¼å¯ä»¥é‡‡ç”¨å’Œå›¾åƒåŸå§‹å°ºå¯¸ä¸€æ ·çš„æ–¹å¼ï¼Œå³é€šè¿‡å‚…ç«‹å¶ç¼–ç å¹¶åŠ åœ¨time embeddingä¸Šã€‚åœ¨æ¨ç†æ—¶ï¼Œæˆ‘ä»¬åªéœ€è¦å°†è¿™ä¸ªåæ ‡è®¾ç½®ä¸º(0, 0)å°±å¯ä»¥å¾—åˆ°ç‰©ä½“å±…ä¸­çš„å›¾åƒï¼ˆæ­¤æ—¶å›¾åƒç›¸å½“äºæ²¡æœ‰è£å‰ªï¼‰ã€‚ä¸‹å›¾å±•ç¤ºäº†é‡‡ç”¨ä¸åŒçš„cropåæ ‡çš„ç”Ÿæˆå›¾åƒå¯¹æ¯”ï¼Œå¯ä»¥çœ‹åˆ°(0, 0)åæ ‡å¯ä»¥ç”Ÿæˆç‰©ä½“å±…ä¸­è€Œæ— ç¼ºå¤±çš„å›¾åƒï¼Œé‡‡ç”¨å…¶å®ƒçš„åæ ‡å°±ä¼šå‡ºç°æœ‰è£å‰ªæ•ˆåº”çš„å›¾åƒã€‚

SDXLåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¯ä»¥å°†ä¸¤ç§æ¡ä»¶æ³¨å…¥ï¼ˆsize and crop conditioningï¼‰ç»“åˆåœ¨ä¸€èµ·ä½¿ç”¨ï¼Œè®­ç»ƒæ•°æ®çš„å¤„ç†æµç¨‹å’Œä¹‹å‰æ˜¯ä¸€æ ·çš„ï¼Œåªæ˜¯è¦é¢å¤–ä¿å­˜å›¾åƒçš„**åŸå§‹widthå’Œheight**ä»¥åŠå›¾åƒ**cropæ—¶çš„å·¦ä¸Šå®šç‚¹åæ ‡topå’Œleft**ï¼Œå…·ä½“çš„æµç¨‹å¦‚ä¸‹æ‰€ç¤ºï¼š

![Untitled](Diffusion%20model%20%E2%80%94%20SDXL%20034fb5c11e2b4b82b3e5931c50a86a6a/Untitled%206.png)

è¿™é‡Œæˆ‘ä»¬ç®€å•æ€»ç»“ä¸€ä¸‹ï¼ŒSDXLæ€»å…±å¢åŠ äº†4ä¸ªé¢å¤–çš„æ¡ä»¶æ³¨å…¥åˆ°UNetï¼Œå®ƒä»¬åˆ†åˆ«æ˜¯pooled text embeddingï¼Œoriginal sizeï¼Œcrop top-left coordå’Œtarget sizeã€‚å¯¹äºåé¢ä¸‰ä¸ªæ¡ä»¶ï¼Œå®ƒä»¬å¯ä»¥åƒtimestepä¸€æ ·é‡‡ç”¨å‚…ç«‹å¶ç¼–ç å¾—åˆ°ç‰¹å¾ï¼Œç„¶åæˆ‘ä»¬è¿™äº›ç‰¹å¾å’Œpooled text embeddingæ‹¼æ¥åœ¨ä¸€èµ·ï¼Œæœ€ç»ˆå¾—åˆ°ç»´åº¦ä¸º2816ï¼ˆ1280+256*2*3ï¼‰çš„ç‰¹å¾ã€‚æˆ‘ä»¬å°†è¿™ä¸ªç‰¹å¾é‡‡ç”¨ä¸¤ä¸ªçº¿æ€§å±‚æ˜ å°„åˆ°å’Œtime embeddingä¸€æ ·çš„ç»´åº¦ï¼Œç„¶ååŠ åœ¨time embeddingä¸Šå³å¯ï¼Œå…·ä½“çš„å®ç°ä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š

```python
import math
from einops import rearrange
import torch

batch_size =16
# channel dimension of pooled output of text encoder (s)
pooled_dim = 1280
adm_in_channels = 2816
time_embed_dim = 1280

def fourier_embedding(inputs, outdim=256, max_period=10000):
    """
    Classical sinusoidal timestep embedding
    as commonly used in diffusion models
    : param inputs : batch of integer scalars shape [b ,]
    : param outdim : embedding dimension
    : param max_period : max freq added
    : return : batch of embeddings of shape [b, outdim ]
    """
    half = outdim // 2
    freqs = torch.exp(
        -math.log(max_period)
            * torch.arange(start=0, end=half, dtype=torch.float32)
            / half
    ).to(device=inputs.device)
    args = timesteps[:, None].float() * freqs[None]
    embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)
    if dim % 2:
        embedding = torch.cat(
            [embedding, torch.zeros_like(embedding[:, :1])], dim=-1
        )
    return embedding

def cat_along_channel_dim(x: torch.Tensor,) -> torch.Tensor:
    if x.ndim == 1:
        x = x[... , None]
 assert x . ndim == 2
 b, d_in = x.shape
    x = rearrange(x, "b din -> (b din)")
    # fourier fn adds additional dimension
    emb = fourier_embedding(x)
    d_f = emb.shape[-1]
    emb = rearrange(emb, "(b din) df -> b (din df)",
                     b=b, din=d_in, df=d_f)
 return emb

def concat_embeddings(
    # batch of size and crop conditioning cf. Sec. 3.2
    c_size: torch.Tensor,
    c_crop: torch.Tensor,
    # batch of target size conditioning cf. Sec. 3.3
    c_tgt_size: torch.Tensor ,
    # final output of text encoders after pooling cf. Sec . 3.1
    c_pooled_txt: torch.Tensor,
) -> torch.Tensor:
    # fourier feature for size conditioning
    c_size_emb = cat_along_channel_dim(c_size)
 # fourier feature for size conditioning
 c_crop_emb = cat_along_channel_dim(c_crop)
 # fourier feature for size conditioning
 c_tgt_size_emb = cat_along_channel_dim(c_tgt_size)
 return torch.cat([c_pooled_txt, c_size_emb, c_crop_emb, c_tgt_size_emd], dim=1)

# the concatenated output is mapped to the same
# channel dimension than the noise level conditioning
# and added to that conditioning before being fed to the unet
adm_proj = torch.nn.Sequential(
    torch.nn.Linear(adm_in_channels, time_embed_dim),
    torch.nn.SiLU(),
    torch.nn.Linear(time_embed_dim, time_embed_dim)
)

# simulating c_size and c_crop as in Sec. 3.2
c_size = torch.zeros((batch_size, 2)).long()
c_crop = torch.zeros((batch_size, 2)).long ()
# simulating c_tgt_size and pooled text encoder output as in Sec. 3.3
c_tgt_size = torch.zeros((batch_size, 2)).long()
c_pooled = torch.zeros((batch_size, pooled_dim)).long()
 
# get concatenated embedding
c_concat = concat_embeddings(c_size, c_crop, c_tgt_size, c_pooled)
# mapped to the same channel dimension with time_emb
adm_emb = adm_proj(c_concat)
```

### **ç»†åŒ–æ¨¡å‹**

SDXLçš„å¦å¤–ä¸€ä¸ªä¼˜åŒ–ç‚¹æ˜¯çº§è”äº†ä¸€ä¸ª**ç»†åŒ–æ¨¡å‹**ï¼ˆ**refiner model**ï¼‰æ¥è¿›ä¸€æ­¥æå‡å›¾åƒè´¨é‡ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![Untitled](Diffusion%20model%20%E2%80%94%20SDXL%20034fb5c11e2b4b82b3e5931c50a86a6a/Untitled%207.png)

è¿™é‡Œç¬¬ä¸€ä¸ªæ¨¡å‹æˆ‘ä»¬ç§°ä¸ºbase modelï¼Œä¸Šè¿°æˆ‘ä»¬è®²çš„å…¶å®å°±æ˜¯SDXL-base modelï¼Œç¬¬äºŒä¸ªæ¨¡å‹æ˜¯refiner modelï¼Œå®ƒæ˜¯è¿›ä¸€æ­¥åœ¨base modelç”Ÿæˆçš„å›¾åƒåŸºç¡€ä¸Šæå‡å›¾åƒçš„ç»†èŠ‚ã€‚refiner modelæ˜¯å’Œbase modelé‡‡ç”¨åŒæ ·VAEçš„ä¸€ä¸ªlatent diffusion modelï¼Œä½†æ˜¯å®ƒåªåœ¨ä½¿ç”¨è¾ƒä½çš„noise levelè¿›è¡Œè®­ç»ƒï¼ˆåªåœ¨å‰200 timestepsä¸Šï¼‰ï¼Œåœ¨æ¨ç†æ—¶ï¼Œæˆ‘ä»¬**åªä½¿ç”¨refiner modelçš„å›¾ç”Ÿå›¾èƒ½åŠ›**ã€‚å¯¹äºä¸€ä¸ªpromptï¼Œæˆ‘ä»¬é¦–å…ˆç”¨base modelç”Ÿæˆlatentï¼Œç„¶åæˆ‘ä»¬ç»™è¿™ä¸ªlatentåŠ ä¸€å®šçš„å™ªéŸ³ï¼ˆé‡‡ç”¨æ‰©æ•£è¿‡ç¨‹ï¼‰ï¼Œå¹¶ä½¿ç”¨refiner modelè¿›è¡Œå»å™ªã€‚ç»è¿‡è¿™æ ·ä¸€ä¸ªé‡æ–°åŠ å™ªå†å»å™ªçš„è¿‡ç¨‹ï¼Œå›¾åƒçš„å±€éƒ¨ç»†èŠ‚ä¼šæœ‰ä¸€å®šçš„æå‡.

çº§è”refiner modelå…¶å®ç›¸å½“äºä¸€ç§æ¨¡å‹é›†æˆï¼Œè¿™ç§é›†æˆç­–ç•¥ä¹Ÿæ—©å·²ç»åº”ç”¨åœ¨æ–‡ç”Ÿå›¾ä¸­ï¼Œæ¯”å¦‚NVIDAåœ¨[eDiff-I: Text-to-Image Diffusion Models with an Ensemble of Expert Denoisers](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2211.01324)å°±æå‡ºäº†é›†æˆä¸åŒçš„æ‰©æ•£æ¨¡å‹æ¥æå‡ç”Ÿæˆè´¨é‡ã€‚å¦å¤–é‡‡ç”¨SDçš„å›¾ç”Ÿå›¾æ¥æå‡è´¨é‡å…¶å®ä¹Ÿæ—©å·²ç»è¢«åº”ç”¨äº†ï¼Œæ¯”å¦‚ç¤¾åŒºå·¥å…·[Stable Diffusion web UI](https://link.zhihu.com/?target=https%3A//github.com/AUTOMATIC1111/stable-diffusion-webui)çš„[high res fix](https://link.zhihu.com/?target=https%3A//github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/6509)å°±æ˜¯åŸºäºå›¾ç”Ÿå›¾æ¥å®ç°çš„ï¼ˆç»“åˆè¶…åˆ†æ¨¡å‹ï¼‰ã€‚

refiner modelå’Œbase modelåœ¨ç»“æ„ä¸Šæœ‰ä¸€å®šçš„ä¸åŒï¼Œå…¶UNetçš„ç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œrefiner modelé‡‡ç”¨4ä¸ªstageï¼Œç¬¬ä¸€ä¸ªstageä¹Ÿæ˜¯é‡‡ç”¨æ²¡æœ‰attentionçš„DownBlock2Dï¼Œç½‘ç»œçš„ç‰¹å¾ç»´åº¦é‡‡ç”¨384ï¼Œè€Œbase modelæ˜¯320ã€‚å¦å¤–ï¼Œrefiner modelçš„attentionæ¨¡å—ä¸­transformer blockæ•°é‡å‡è®¾ç½®ä¸º4ã€‚refiner modelçš„å‚æ•°é‡ä¸º2.3Bï¼Œç•¥å°äºbase modelã€‚

![Untitled](Diffusion%20model%20%E2%80%94%20SDXL%20034fb5c11e2b4b82b3e5931c50a86a6a/Untitled%208.png)

å¦å¤–refiner modelçš„text encoderåªä½¿ç”¨äº†OpenCLIP ViT-bigGï¼Œä¹Ÿæ˜¯æå–å€’æ•°ç¬¬äºŒå±‚ç‰¹å¾ä»¥åŠpooled text embedã€‚ä¸base modelä¸€æ ·ï¼Œrefiner modelä¹Ÿä½¿ç”¨äº†size and crop conditioningï¼Œé™¤æ­¤ä¹‹å¤–è¿˜å¢åŠ äº†å›¾åƒçš„è‰ºæœ¯è¯„åˆ†[aesthetic-score](https://link.zhihu.com/?target=https%3A//github.com/christophschuhmann/improved-aesthetic-predictor)ä½œä¸ºæ¡ä»¶ï¼Œå¤„ç†æ–¹å¼å’Œä¹‹å‰ä¸€æ ·ã€‚refiner modelåº”è¯¥æ²¡æœ‰é‡‡ç”¨å¤šå°ºåº¦å¾®è°ƒï¼Œæ‰€ä»¥æ²¡æœ‰å¼•å…¥target sizeä½œä¸ºæ¡ä»¶ï¼ˆrefiner modelåªæ˜¯ç”¨æ¥å›¾ç”Ÿå›¾ï¼Œå®ƒå¯ä»¥ç›´æ¥é€‚åº”å„ç§å°ºåº¦ï¼‰ã€‚