# style transfer

[Stylebrush](style%20transfer%2014771bdab3cf80e6b5ecd51c18808e31/Stylebrush%20bd9a4a57c7574ae2b54776ba6209fcc6.md)

- [ ]  Animate anyone
- [ ]  Kolors
- [ ]  Vidéo diffusion models
- [ ]  Animatediff
- [ ]  LDM
- [ ]  StyleAdapter (Wang et al. [2023](https://arxiv.org/html/2408.09496v1#bib.bib33)) and InstantStyle (Wang et al. [2024](https://arxiv.org/html/2408.09496v1#bib.bib32)); inversion and shared attention-based methods like StyleAlign (Wu et al. [2021b](https://arxiv.org/html/2408.09496v1#bib.bib38)) and Visual Style Prompting (Jeong et al. [2024](https://arxiv.org/html/2408.09496v1#bib.bib17)); as well as test-time fine-tuning approaches such as StyleDrop (Sohn et al. [2023](https://arxiv.org/html/2408.09496v1#bib.bib27)).
- [ ]  Ipadapter
- [ ]  Spatial attention
- [ ]  Moore AnimateAnyone
- [ ]  Stable diffusion enlarge image
- [ ]  Style ID https://arxiv.org/pdf/2312.09008
- [ ]  InstantStyle-Plus: Style Transfer with Content-Preserving in Text-to-Image Generation

[https://github.com/diyiiyiii/StyTR-2](https://github.com/diyiiyiii/StyTR-2)

[https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_StyTr2_Image_Style_Transfer_With_Transformers_CVPR_2022_paper.pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_StyTr2_Image_Style_Transfer_With_Transformers_CVPR_2022_paper.pdf)